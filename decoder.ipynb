{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Rate is  26 frames per second\n",
      "Frame count :  787.0\n"
     ]
    }
   ],
   "source": [
    "original = cv.VideoCapture('./1tagvideo.mp4')\n",
    "if (original.isOpened() == False):\n",
    "\tprint(\"Error opening the video file\")\n",
    "else:\n",
    "  # Get fps\n",
    "  fps = int(original.get(5))\n",
    "  print(\"Frame Rate is \",fps,\"frames per second\")\t\n",
    "  # Get total frame count\n",
    "  frame_count = original.get(7)\n",
    "  print(\"Frame count : \", frame_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit rectangles given the list of corners\n",
    "def detect_rectangles(corners:list()):\n",
    "    point_pairs = []\n",
    "    # Create a list of point pairs\n",
    "    for point_pairs in itertools.combinations(corners,2):\n",
    "        p1,p2= point_pairs[0],point_pairs[1]\n",
    "        dist = np.linalg.norm(p1-p2)\n",
    "        if(dist>50):\n",
    "            slope = 0\n",
    "            center =  np.array([(p1[0]+p2[0])/2,(p1[1]+p2[1])/2])\n",
    "            point_pairs.append([p1,p2,slope,center,dist])\n",
    "               \n",
    "    possible_corners = np.array(point_pairs,dtype=object)\n",
    "    possible_corners = possible_corners[np.argsort(possible_corners[:,-1])][::-1]\n",
    "    \n",
    "    rectangles = []\n",
    "    center_lengths = []\n",
    "    \n",
    "    # Create a list of points such that the lines formed by them have similar lengths and mid point coordinates\n",
    "    for line_pairs in itertools.combinations(possible_corners,2):\n",
    "        n,m = line_pairs[0],line_pairs[1]\n",
    "        if(np.abs(n[-1]-m[-1])>10):\n",
    "            continue\n",
    "        if (np.linalg.norm(m[3]-n[3])>10):\n",
    "            continue\n",
    "        rectangles.append(np.array([tuple(n[0].tolist()),tuple(m[0].tolist()),tuple(n[1].tolist()),tuple(m[1].tolist())]))\n",
    "        center_lengths.append(np.array([n[3],np.linalg.norm(n[0]-m[0])],dtype = object))\n",
    "    return rectangles,center_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_polygon(img, lov):\n",
    "    for i in lov:\n",
    "        pts = np.array(i, np.int32)\n",
    "        pts = pts.reshape((-1,1,2))\n",
    "        img_rect = cv.polylines(img,[pts],True,(0,255,255))\n",
    "    return img_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Homography\n",
    "def calculate_homography(world_corners,image_corner):\n",
    "    #4 points in the world frame\n",
    "    Xw = world_corners\n",
    "    # 4 points in the camera frame\n",
    "    xc = image_corner\n",
    "    # intermediary matrix to calculate the homography\n",
    "    matrix_A = np.matrix(np.zeros((8,9)))\n",
    "    # Populate the martrix\n",
    "    for a,b in zip(enumerate(Xw),enumerate(xc)):\n",
    "        i,j,n,m = a[0],b[0],a[1],b[1]\n",
    "        matrix_A[i+j,:] = -n[0],-n[1],-1,0,0,0,m[0]*n[0],m[0]*n[1],m[0]\n",
    "        matrix_A[(i+j)+1,:] = 0,0,0,-n[0],-n[1],-1,m[1]*n[0],m[1]*n[1],m[1]\n",
    "    # Calculate the psudo inverse of the matrix\n",
    "    U,S,V = np.linalg.svd(matrix_A)\n",
    "    # The vector with the smallest eigen value is the solution to the equation\n",
    "    H = np.reshape(V[-1],[3,3])\n",
    "    return H/H[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode the tag given a cropped image \n",
    "def decode_tag(tag):\n",
    "    # Threshold the image to a binary image\n",
    "    tag = cv.cvtColor(tag,cv.COLOR_BGR2GRAY)\n",
    "    _,tag = cv.threshold(tag,127,255,cv.THRESH_OTSU+cv.THRESH_OTSU)\n",
    "    # Split the image into 8 equal segments\n",
    "    tag_grids = np.array_split(tag,8)\n",
    "    msg = np.zeros((8,8))\n",
    "    # Iterate over all segments and average each segment into the binary value\n",
    "    for i,tag_grid in enumerate(tag_grids):\n",
    "        for j,grid in  enumerate(np.array_split(tag_grid,8,axis=1)):\n",
    "            if np.count_nonzero(grid) < 0.5*grid.size:\n",
    "                msg[i][j] = 0\n",
    "            else:\n",
    "                msg[i][j] =1\n",
    "    # assign the orientation of the tag based on the 3rd row/column\n",
    "    if msg[2][2]:\n",
    "        ori = 180\n",
    "    elif msg[2][5]:\n",
    "        ori = 90\n",
    "    elif msg[5][2]:\n",
    "        ori = 270\n",
    "    elif msg[5][5]:\n",
    "        ori = 0\n",
    "    else :\n",
    "        ori = None\n",
    "    # Assign the ID of the tag\n",
    "    idx = (int(msg[3,3])*1+int(msg[3,4])*2+int(msg[4,4])*4+int(msg[4,3])*8)\n",
    "    # Rotate the ID given the orientation\n",
    "    idx = ((idx<<(ori//90)&0b1111)|(idx>>(4-(ori//90))))\n",
    "    # If the border condition is not met then return None\n",
    "    if((msg[0:2]!=0).any() and (msg[:][0:2]!=0).any() and (msg[6:-1][:]!=0).any() and (msg[:][6:-1]!=0).any()):\n",
    "        return np.nan,None,None\n",
    "    \n",
    "    return msg,ori,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp the image with the given size and template image\n",
    "def Warping(src, homography, size, template = None):\n",
    "    y, x = np.indices((size[0], size[1]))\n",
    "    ## Create an array with values equal to coordinates of the point\n",
    "    cam_pts = np.stack((x.ravel(), y.ravel(), np.ones(x.size)))\n",
    "    h_inv = np.linalg.inv(homography)\n",
    "    \n",
    "    ## Find the transformation that maps the camera point to the world point\n",
    "    cam_pts = h_inv.dot(cam_pts)\n",
    "    ## Normalize so that the Z is 1\n",
    "    cam_pts /= cam_pts[2,:]\n",
    "\n",
    "    ## Floor the float values to a interger value\n",
    "    xw, yw = cam_pts[:2,:].astype(int)\n",
    "    # padding\n",
    "    xw[xw >=  src.shape[1]] = src.shape[1]\n",
    "    xw[xw < 0] = 0\n",
    "    yw[yw >=  src.shape[0]] = src.shape[0]\n",
    "    yw[yw < 0] = 0\n",
    "    ## If a template image is provided then map that to world frame\n",
    "    if (type(template)==np.ndarray):\n",
    "        src[yw, xw, :] = template[y.ravel(), x.ravel(), :]\n",
    "        return src\n",
    "    ## Map the world frame to the given the camera frame\n",
    "    else:\n",
    "        warped_image = np.zeros((size[0],size[1], 3))\n",
    "        warped_image[y.ravel(), x.ravel(), :]= src[yw, xw, :]\n",
    "        return warped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the points so that the are in anti clockwise \n",
    "def sort_points(points):\n",
    "    left_most = points[np.argmin(points[:,0])]\n",
    "    right_most = points[np.argmax(points[:,0])]\n",
    "    topmost = points[np.argmin(points[:,1])]\n",
    "    bottommost = points[np.argmax(points[:,1])]\n",
    "    return [left_most,bottommost,right_most,topmost]\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video():\n",
    "    frames = []\n",
    "    out = cv.VideoWriter('outpy.avi',cv.VideoWriter_fourcc('M','J','P','G'), 26, (1920,1080))\n",
    "    testudo  =cv.imread('testudo.jpg')\n",
    "    previous_tag=None\n",
    "    while( original.isOpened()):\n",
    "        #  original.read() methods returns a tuple, first element is a bool \n",
    "        # and the second is frame\n",
    "        ret, frame =  original.read()\n",
    "        if ret == True:\n",
    "        #Split the channels and invert color of the frame as we are only interested in the red channel\n",
    "            frames.append(frame)\n",
    "            gaussian = np.array([[-1,-2,-1], [-2 ,13.5,-2], [-1,-2,-1]])# Sharpen the image to hightlight edges\n",
    "            img = frame #assign the frame of interest\n",
    "            new_img = cv.medianBlur(img, 5) # Blur the image slightly to remove noise\n",
    "            new_img = cv.filter2D(new_img,-1,gaussian) #Sharpen the image to get the edges more promanent \n",
    "            gray = cv.cvtColor(new_img,cv.COLOR_BGR2GRAY) #convert to grayscale\n",
    "\n",
    "            #Perform corner detection\n",
    "            corners = cv.goodFeaturesToTrack(gray,30,0.1,35) # only 30 points are selected\n",
    "            corners = np.int0(corners)\n",
    "            list_of_corners = []\n",
    "            for i in corners:\n",
    "                x,y = i.ravel()\n",
    "                list_of_corners.append(np.array([x,y]))\n",
    "            # Given the list of corners, fit quads to the images\n",
    "            rectangles,d=detect_rectangles(list_of_corners)\n",
    "            tags = []\n",
    "            # For every quad calculate the Homography matrix that converts the world point to the camera plane\n",
    "            for i, rectangle in enumerate(rectangles):\n",
    "                # MAKE IT TO THE CLOSEST MULTIPLE OF 8 the side length of tag\n",
    "                max_frame_size = int(d[i][1])+(int(d[i][1])%8)\n",
    "                # The points on the image plane that will be mapped to the world plane\n",
    "                PoF = [[0,0],[max_frame_size,0],[max_frame_size,max_frame_size],[0,max_frame_size]]\n",
    "                # Sort the list of points such that the points are in the clockwise sense\n",
    "                rectangle = sort_points(rectangle)\n",
    "                # Calculate the homography using SVD\n",
    "                homo = calculate_homography(rectangle[::-1],PoF)\n",
    "                try:\n",
    "                    warped_img = np.uint8(Warping(img,homo,(max_frame_size,max_frame_size)))\n",
    "                    # Decode the same image assuming its a TAG\n",
    "                    msg,ori,idx = decode_tag(warped_img)\n",
    "                except:\n",
    "                    continue\n",
    "                # Add it to the list of tags\n",
    "                tags.append([rectangle,msg,ori,idx,max_frame_size,homo])\n",
    "                \n",
    "                # For every quad that returned a valid tag info superimpose a image\n",
    "                tag = tags[-1]\n",
    "                if(np.isnan(tag[1]).any() or type(tag[2])==type(None) or type(tag[3])==type(None)):\n",
    "                    continue\n",
    "                if(tag[3]!=7):\n",
    "                    continue\n",
    "                previous_tag = tag\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "        print(len(frames)) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/manu/enpm673/Project 1/Final/decoder.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000015?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000015?line=1'>2</a>\u001b[0m     process_video()\n",
      "\u001b[1;32m/home/manu/enpm673/Project 1/Final/decoder.ipynb Cell 9'\u001b[0m in \u001b[0;36mprocess_video\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000014?line=24'>25</a>\u001b[0m     list_of_corners\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39marray([x,y]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000014?line=25'>26</a>\u001b[0m \u001b[39m# Given the list of corners, fit quads to the images\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000014?line=26'>27</a>\u001b[0m rectangles,d\u001b[39m=\u001b[39mdetect_rectangles(list_of_corners)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000014?line=27'>28</a>\u001b[0m tags \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000014?line=28'>29</a>\u001b[0m \u001b[39m# For every quad calculate the Homography matrix that converts the world point to the camera plane\u001b[39;00m\n",
      "\u001b[1;32m/home/manu/enpm673/Project 1/Final/decoder.ipynb Cell 3'\u001b[0m in \u001b[0;36mdetect_rectangles\u001b[0;34m(corners)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000004?line=8'>9</a>\u001b[0m         slope \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000004?line=9'>10</a>\u001b[0m         center \u001b[39m=\u001b[39m  np\u001b[39m.\u001b[39marray([(p1[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39mp2[\u001b[39m0\u001b[39m])\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m,(p1[\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39mp2[\u001b[39m1\u001b[39m])\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000004?line=10'>11</a>\u001b[0m         point_pairs\u001b[39m.\u001b[39;49mappend([p1,p2,slope,center,dist])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000004?line=12'>13</a>\u001b[0m possible_corners \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(point_pairs,dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/manu/enpm673/Project%201/Final/decoder.ipynb#ch0000004?line=13'>14</a>\u001b[0m possible_corners \u001b[39m=\u001b[39m possible_corners[np\u001b[39m.\u001b[39margsort(possible_corners[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])][::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    process_video()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d002c88899aefa9981c869b211d493db0c55adb45f78cd2d618ec0e7130067d5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
